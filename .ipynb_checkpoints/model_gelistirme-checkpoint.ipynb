{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b3b1b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import imghdr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "import PIL\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "06b23368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 383 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory(\"TRAIN/\", image_size=(224,224), label_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9f19376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x, y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d25dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = next(iter(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a278077c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([224, 224, 3])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9697e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "pretrained_model_without_top_layer = hub.KerasLayer(\n",
    "    feature_extractor_model, input_shape=(224, 224,3), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2df7c9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1280)              1639680   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,898,945\n",
      "Trainable params: 1,640,961\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "number_of_classes = 1\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    pretrained_model_without_top_layer,\n",
    "    \n",
    "    tf.keras.layers.Dense(1280, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(number_of_classes, activation=\"sigmoid\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0c6b50fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12/12 [==============================] - 12s 679ms/step - loss: 0.3463 - acc: 0.8668\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 10s 782ms/step - loss: 0.0143 - acc: 0.9922\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 11s 857ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 12s 868ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 10s 713ms/step - loss: 4.1413e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21e0b48b8e0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[\"acc\"]\n",
    "    \n",
    ")\n",
    "\n",
    "model.fit(data, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f719d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "image = Image.open(\"dataval/output/frame_forestsmoke32_120.jpg\").resize((224,224))\n",
    "image = np.array(image)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fb81f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.09331036]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = model(np.expand_dims(image, axis=0))\n",
    "logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e5296634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test = tf.keras.utils.image_dataset_from_directory(\"TEST/\", image_size=(224,224))\n",
    "test = test.map(lambda x, y: (x/255,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91d39a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 260ms/step - loss: 0.4834 - acc: 0.8095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48342204093933105, 0.8095238208770752]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2ac58d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.8838864]], dtype=float32)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL.Image as Image\n",
    "image = Image.open(\"test_exmp/frame_vid7_840.jpg\").resize((224,224))\n",
    "image = np.array(image)/255\n",
    "logit = model(np.expand_dims(image, axis=0))\n",
    "logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a70e34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
